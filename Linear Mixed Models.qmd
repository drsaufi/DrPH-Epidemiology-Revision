---
title: "Linear Mixed Models"
subtitle: "Advanced Numerical Data Analysis"
author: "Dr Muhammad Saufi"
date: last-modified
format: 
  html:
    toc: true
    toc-title: Contents
    toc-location: left
    toc-depth: 5
    toc-expand: 1
    number-sections: true
    code-fold: true
    code-summary: "Show the code"
    code-link: true
    theme:
      light: united
      dark: cyborg
editor: visual
include-after-body: "footer.html"
---

# Loading Packages

```{r}
library(haven)
library(tidyverse)
library(broom.mixed)
library(here)
library(gtsummary)
library(DT)
library(kableExtra)
library(lme4)
library(lmerTest)
library(dplyr)
```

# Dataset

The dataset is from the Scottish School Leavers Survey (SSLS). It is a longitudinal dataset that captures information on several cohorts of young people over time.

**Hierarchy**: The dataset has a hierarchical structure with students (level 1) nested within schools (level 2).

-   **Level 1 (Students)**: Individual students identified by `caseid`.
-   **Level 2 (Schools)**: Schools identified by `schoolid`.

**Dependent Variable**:

-   `score`: Total attainment score of the student, ranging from 0 to 75.

**Explanatory Variables**:

-   `cohort90`: Year of the cohort, represented by subtracting 1990 from each value. Values range from -6 (1984) to 8 (1998), with 0 representing 1990.
-   `female`: Gender of the student (1 = female, 0 = male).
-   `sclass`: Social class of the student, defined as the higher class of mother or father (1 = managerial and professional, 2 = intermediate, 3 = working, 4 = unclassified).
-   `schtype`: Type of school (1 = independent, 0 = state-funded).
-   `schurban`: Urban-rural classification of the school (1 = urban, 0 = town or rural).
-   `schdenom`: School denomination (1 = Roman Catholic, 0 = non-denominational).

## Load the Dataset

```{r}
score.sch <- read_dta("score.sch_data.dta")
glimpse(score.sch)
```

## Data Wrangling

Numerical variables are often converted to factors to facilitate easier analysis and interpretation.

```{r}
score.sch <- score.sch %>%
  mutate(
    female2 = factor(female, labels = c('male', 'female')),
    class2 = factor(sclass, labels = c('managerial+prof', 'intermediate', 'working', 'unclassified')),
    schtype2 = factor(schtype, labels = c('state-funded', 'independent')),
    schurban2 = factor(schurban, labels = c('town/rural', 'urban')),
    schdenom2 = factor(schdenom, labels = c('state-funded', 'independent')))
glimpse(score.sch)
```

## Exploratory Data Analysis

Summarize the data and create some basic plots.

### Descriptive Table

```{r}
score.sch %>% tbl_summary()
```

### Plot 1

```{r}
score.sch %>%
  ggplot(aes(x = cohort90, y = score)) +
  geom_point() +
  geom_smooth(method = lm)
```

**Comment:** This graph displays the relationship between `cohort90` and `score`, along with a fitted linear regression line. The graph suggests that student attainment scores have generally increased over the years from 1984 to 1998. However, there is a substantial amount of variability in the scores within each cohort year. The positive slope of the regression line quantifies the trend of improvement in scores over time.

### Plot 2

```{r}
score.sch %>%
  ggplot(aes(x = cohort90, y = score, col = female, group = female)) +
  geom_point() +
  geom_smooth(method = lm)
```

**Comment:** This graph shows the relationship between `cohort90` and `score`, with a distinction between male and female students. The graph indicates that both male and female students have experienced improvements in attainment scores over the years from 1984 to 1998. The trends for both genders are very similar, suggesting that gender does not play a significant role in the difference in attainment scores within this dataset. The upward slope of both lines quantifies the overall improvement in scores over time, and the color differentiation helps visualize the gender distribution within each cohort.

# Multilevel Model

Multilevel model, also known as a hierarchical linear model or mixed-effects model, accounts for the nested structure of the data. In this dataset, students are nested within schools.

## Null Model (Simplest Model)

The simplest form of a multilevel model is the null model, which does not include any explanatory variables. It only includes random intercepts for the groups (schools in this case). The null model helps in understanding how much of the total variance in the outcome variable (score) can be attributed to differences between groups (schools).

The equation for the null model is: $$
score_{ij} = \beta_0 + u_{0j} + e_{ij}
$$

-   $score_{ij}$ is the attainment score of student $i$ in school $j$.
-   $\beta_0$ is the overall mean score across all schools.
-   $u_{0j}$ is the random effect for school $j$, capturing the deviation of school $j$'s mean score from the overall mean.
-   $e_{ij}$ is the residual error term for student $i$ in school $j$.

## Single-Level Analysis

A single-level analysis uses a standard linear regression model assuming that all data points are independent and the outcome is normally distributed.

```{r}
m.lm <- lm(score ~ 1, data = score.sch)
summary(m.lm)
```

**Summary of the Output**

1.  **Call**: `lm(formula = score ~ 1, data = score.sch)`

    -   This indicates that a linear model is being fitted with `score` as the response variable and no predictors (only an intercept).

2.  **Residuals**: The residuals section provides a summary of the distribution of the residuals (differences between observed and predicted values):

    -   **Min**: -31.095
    -   **1Q (First Quartile)**: -12.095
    -   **Median**: 1.905
    -   **3Q (Third Quartile)**: 13.905
    -   **Max**: 43.905

3.  **Coefficients**: The coefficients section provides the estimate of the model's intercept:

    -   **Estimate**: 31.09462 This is the estimated mean score for all students.
    -   **Std. Error**: 0.09392 This is the standard error of the intercept estimate, indicating the precision of the estimate.
    -   **t value**: 331.1 This is the t-statistic for testing whether the intercept is significantly different from zero.
    -   **Pr(\>\|t\|)**: \<2e-16 This is the p-value associated with the t-statistic, indicating that the intercept is highly significant (p \< 0.001).

4.  **Residual Standard Error**:

    -   **Residual standard error**: 17.31 on 33987 degrees of freedom
    -   This value measures the average distance that the observed scores fall from the regression line (mean score). A lower residual standard error indicates a better fit.

5.  **Interpretation**:

    i)  **Overall Mean Score**: The overall mean score for students is estimated to be 31.09462. This value is statistically significant, as indicated by the extremely small p-value (p \< 0.001).

    ii) **Residuals**: The residuals indicate the spread of the differences between observed scores and the estimated mean score. The range of residuals (-31.095 to 43.905) suggests variability in scores around the mean.

    iii) **Model Fit**: The residual standard error of 17.31 suggests that there is considerable variability in student scores around the mean. This model does not account for any grouping structure (such as schools), meaning it assumes all observations are independent.

6.  **Equation**:

    -   $\hat{\text{score}} = \beta_0$
    -   $\hat{\text{score}} = 31.09462$

7.  **Conclusion**: The single-level analysis provides an estimate of the overall mean score (31.09462) for all students, which is highly significant. However, the residual standard error and the spread of residuals indicate that there is substantial variability in scores that is not explained by this simple model. This highlights the potential need for a more complex model, such as a multilevel model, to account for the nested structure of the data and potentially explain some of the variability in scores.

## Multilevel Analysis

Multilevel analysis (also known as hierarchical linear modeling or mixed-effects modeling) is used to analyze data that has a nested structure. In this dataset, students are nested within schools. This type of analysis allows us to account for variability at both the student level and the school level, providing more accurate estimates and inferences.

1.  **Fixed Effects:** The overall mean score $\beta_0$ is estimated. These are the effects that are assumed to be constant across all groups. For example, the average effect of a variable like cohort90 on score across all students and schools.

2.  **Random Effects:** These allow for variability between groups. For example, different schools may have different baseline scores (intercepts), and the effect of cohort90 on score may vary between schools.

-   **Between-School Variance**: Variance due to differences between schools $u_{0j}$.
-   **Within-School Variance**: Variance due to differences within schools $e_{ij}$.

```{r}
m0 <- lmer(score ~ 1 + (1 | schoolid), data = score.sch, REML = FALSE)
summary(m0)
```

**Summary of the Output**

1.  **Fixed Effects**: The estimated overall mean score across all schools is 30.6006. This value is statistically significant with a very small p-value (\< 2e-16), indicating that the mean score is significantly different from zero.

2.  **Random Effects**

    -   The variance of the school-level intercepts (i.e., the variability in the mean scores between schools) is 61.02, with a standard deviation of 7.812.
    -   The variance of the residual errors (i.e., the variability in scores within schools) is 258.36, with a standard deviation of 16.073.

3.  **Model Fit Statistics**

    -   **AIC**: 286545.1, **BIC**: 286570.4
    -   These statistics provide measures of the model fit. Lower AIC and BIC values indicate a better-fitting model.

4.  **Scaled Residuals**: These are the quartiles of the residuals, which provide information about the distribution of the residuals.

5.  **Interpretation**

    i)  **Overall Mean Score**: The overall mean score for students across all schools is 30.6006, which is statistically significant.

    ii) **Variance Components**:

        -   The between-school variance (61.02) indicates that there is variability in mean scores between different schools.
        -   The within-school variance (258.36) indicates that there is substantial variability in scores within schools.

    iii) **Intraclass Correlation Coefficient (ICC)**: $$
         \text{ICC} = \frac{\sigma^2_{\text{between}}}{\sigma^2_{\text{between}} + \sigma^2_{\text{within}}} = \frac{61.02}{61.02 + 258.36} \approx 0.191
         $$

    -   The ICC can be calculated to understand the proportion of total variance that is attributable to the grouping structure (schools in this case).
    -   Approximately 19.1% of the total variance in scores is attributable to differences between schools, while the remaining 80.9% is due to differences within schools.

6.  **Equation** ${score}_{ij} = 30.6006 + u_{0j} + e_{ij}$

    -   $\beta_0 = 30.6006$ is the fixed effect (overall mean score).
    -   $u_{0j} \sim N(0, 61.02)$ is the random effect for school ( j ) with a variance of 61.02.
    -   $e_{ij} \sim N(0, 258.36)$ is the residual error term for student ( i ) in school ( j ) with a variance of 258.36.

7.  **Conclusion**: The multilevel analysis shows that there is significant variability in student scores both within and between schools. The mean score across all schools is estimated to be 30.6006, with substantial variability observed within schools and some variability observed between schools. The intraclass correlation coefficient (ICC) indicates that a meaningful proportion (19.1%) of the total variance in scores can be attributed to differences between schools. This justifies the use of a multilevel model, as it captures the hierarchical structure of the data and provides a more nuanced understanding of the variability in student scores.

### Random Intercept Models

Random intercept models are a type of multilevel model where each group (e.g., school) has its own intercept but shares the same slope for explanatory variables. This allows the model to account for the fact that different groups may have different baseline levels of the outcome variable.

#### Add an Explanatory Variable

Adding an explanatory variable (predictor) to the random intercept model helps to explain some of the variability in the outcome variable. This allows us to understand how much of the variability is due to the predictor, in addition to the variability captured by the random intercepts.

$$ 
\text{score}_{ij} = \beta_0 + \beta_1 \text{cohort90}_{ij} + u_{0j} + e_{ij} 
$$ This equation represents a random intercept model with one explanatory variable (`cohort90`):

-   $\text{score}_{ij}$: The score for student $i$ in school $j$.
-   $\beta_0$: The overall intercept, representing the average score when all predictors are zero. This is the fixed effect for the intercept.
-   $\beta_1 \text{cohort90}_{ij}$: The fixed effect of the explanatory variable `cohort90` on the score. $\beta_1$ is the coefficient that quantifies how much the score changes with each unit change in `cohort90`.
-   $u_{0j}$: The random effect for school $j$. This term captures the deviation of school $j$'s intercept from the overall intercept $\beta_0$. It accounts for the fact that different schools may have different baseline scores.
-   $e_{ij}$: The residual error term for student $i$ in school $j$. This term captures the deviation of the individual student's score from their school's mean score, after accounting for the effects of `cohort90` and the school-level random intercept.

```{r}
# Adding an explanatory variable (cohort90)
ri_model <- lmer(score ~ cohort90 + (1 | schoolid), data = score.sch, REML = FALSE)
summary(ri_model)
```

```{r}
tidy(ri_model, conf.int = TRUE) %>% kbl %>% kable_styling()
```

**Summary of the Output**

1.  **Fixed Effects**:

    -   **(Intercept)**: The estimated overall mean score when `cohort90` is zero is 30.56. This value is statistically significant with a very small p-value (\< 2e-16), indicating that the intercept is significantly different from zero.
    -   **cohort90**: The coefficient for `cohort90` is 1.215. This means that for each unit increase in `cohort90`, the score increases by 1.215 points on average. This effect is also highly significant (p \< 2e-16).

2.  **Random Effects**:

    -   **schoolid (Intercept)**: **Variance**: 45.99, **Std.Dev.**: 6.781. This indicates that the variance of the school-level intercepts (i.e., the variability in the mean scores between schools) is 45.99, with a standard deviation of 6.781.
    -   **Residual**: **Variance**: 219.29, **Std.Dev.**: 14.808. This indicates the variance of the residual errors (i.e., the variability in scores within schools) is 219.29, with a standard deviation of 14.808.
    -   **Number of Observations**: 33,988 students
    -   **Number of Groups (schools)**: 508 schools

3.  **Model Fit Statistics**: These statistics provide measures of the model fit. Lower AIC and BIC values indicate a better-fitting model.

    -   **AIC**: 280921.6, **BIC**: 280955.3

4.  **Scaled Residuals**: These are the quartiles of the residuals, which provide information about the distribution of the residuals.

    -   **Min**: -3.1487, **1Q**: -0.7242, **Median**: 0.0363, **3Q**: 0.7339, **Max**: 3.7097

5.  **Interpretation**:

    i.  **Overall Mean Score**: The overall mean score for students, when `cohort90` is zero, is estimated to be 30.56.
    ii. **Effect of cohort90**: The score increases by 1.215 points for each unit increase in `cohort90`. This indicates a positive relationship between `cohort90` and `score`.
    iii. **Variance Components**: The variance of the school-level random intercepts is 45.99, indicating variability in mean scores between schools. The residual variance is 219.29, indicating variability in scores within schools.
    iv. **Intraclass Correlation Coefficient (ICC)**: Approximately 17.3% of the total variance in scores is attributable to differences between schools, while the remaining 82.7% is due to differences within schools. $$
        \text{ICC} = \frac{\sigma^2_{\text{between}}}{\sigma^2_{\text{between}} + \sigma^2_{\text{within}}} = \frac{45.99}{45.99 + 219.29} \approx 0.173
        $$
    v.  **Model Fit**: The model fit statistics (AIC, BIC, logLik, deviance) suggest that the model fits the data reasonably well. Lower AIC and BIC values compared to other models would indicate a better fit.

6.  **Conclusion**: The random intercept model with `cohort90` as an explanatory variable shows that there is significant variability in student scores both within and between schools. The average score increases with higher values of `cohort90`, suggesting a positive trend over time or across cohorts. The random intercepts capture the variability between schools, and the residual variance captures the variability within schools. The intraclass correlation coefficient (ICC) indicates that a meaningful proportion of the variance in scores is due to differences between schools, justifying the use of a multilevel model.

#### Prediction

In multilevel modeling, the goal of prediction is to estimate the outcome variable (in this case, `score`) for each individual observation by considering both the fixed effects and the random effects. This allows for more accurate predictions by taking into account the hierarchical structure of the data. The general form of the prediction equation in a random intercept model with one explanatory variable (`cohort90`) is: $$
 \text{score}_{ij} = \beta_0 + \beta_1 \text{cohort90}_{ij} + u_{0j} + e_{ij}
$$

##### Steps for Prediction

1.  Fitting the model - use the random intercept model using the `lmer` function earlier.

2.  Generating Predicted Values To generate predicted values for the outcome variable, use the `fitted` function. This function provides the fitted values (predictions) for each observation in the dataset based on the fixed and random effects:

```{r}
pred_score <- fitted(ri_model)
head(pred_score, 10)  # Display the first 10 predicted scores
```

3.  Extracting Random Effects The random effects (school-specific intercepts) can be extracted using the `ranef` function. This provides the deviations of each school's intercept from the overall intercept:

```{r}
rand_ef <- ranef(ri_model)
head(rand_ef$schoolid, 12)  # Display the random intercepts for the first 12 schools
```

4.  Using `broom.mixed::augment` The `broom.mixed` package's `augment` function creates a data frame that includes the original data, fitted values, and residuals. This can be useful for further analysis and visualization:

```{r}
ri_fitted <- augment(ri_model)
ri_fitted %>% slice(1:12)  # Display the first 12 rows of the augmented data frame
```

##### Explanation

1.  **Fixed Effects**:
    -   The fixed effects ($\beta_0$ and $\beta_1$) provide the overall intercept and the effect of `cohort90` on `score`.
    -   These effects are assumed to be the same across all schools.
2.  **Random Effects**:
    -   The random effects ($u_{0j}$) represent the school-specific deviations from the overall intercept.
    -   Each school has its own intercept, which is the sum of the overall intercept ($\beta_0$) and the school's random intercept ($u_{0j}$).
3.  **Residuals**:
    -   The residuals ($e_{ij}$) represent the individual-specific deviations from the school's predicted score.
    -   These capture the within-school variability that is not explained by the model.
4.  **Combined Prediction**:
    -   The predicted score for each student is the sum of the overall intercept, the effect of `cohort90`, the school-specific random intercept, and the individual-specific residual.
    -   This combined approach ensures that the prediction accounts for both the fixed effects (common to all students) and the random effects (specific to each school).

##### Confirmation with Manual Calculation

Manually calculate the fitted values (predicted scores) to confirm the results from the model.

1.  **Intercept (**$\beta_0$): 30.55915. This is the overall average score when `cohort90` is zero.

2.  **Level-2 Residual (school level residual,** $u_{0j}$): For `schoolid = 1`, this is -6.73. This represents the deviation of this school's intercept from the overall intercept.

3.  **Coefficient for `cohort90` (**$\beta_1$): 1.214955. This indicates the average change in score for each unit change in `cohort90`.

4.  **Example**: For the first observation = **cohort90**: -6, **schoolid**: 1

    -   The fitted value (predicted score) can be calculated as: $$ 
        \text{score}_{ij} = \beta_0 + \beta_1 \text{cohort90}_{ij} + u_{0j} + e_{ij} 
        $$

    -   Since $e_{ij}$ (the individual-level residual) is what we are trying to predict, we simplify to: $$ 
        \text{score}_{ij} = \beta_0 + \beta_1 \text{cohort90}_{ij} + u_{0j} 
        $$

    -   Using the provided values: $$ 
        \text{score}_{ij} = 30.55915 - 6.728309492 + 1.214955 \times (-6) 
        $$ $$ 
        \text{score}_{ij} = 30.55915 - 6.728309492 - 7.28973 
        $$ $$ 
        \text{score}_{ij} = 16.54111 
        $$

    -   This matches the calculated fitted value.

#### Plot

Plotting the model helps to visualize the fitted values from a random intercept model with an explanatory variable, such as `cohort90`. Visualization helps in understanding the model fit and the relationship between the variables.

```{r}
ggplot(ri_fitted, aes(cohort90, .fitted, group = schoolid)) +
  geom_point(alpha = 0.3) +
  geom_line(alpha = 0.3) +
  ylab('Fitted score attainment') +
  xlab('Year: where 0 is the year 1990') +
  ggtitle('The fitted value for random intercept model with covariate cohort90') +
  theme_bw()
```

**Comment**: This plot visualizes the fitted values from the random intercept model with cohort90 as the explanatory variable. It provides a visual confirmation of the model's results, showing how the fitted scores vary across different cohort years and schools. The general upward trend indicates improving scores over time, while the variation between schools highlights the importance of accounting for school-specific effects in the model. This visualization helps in understanding the combined impact of fixed and random effects on the predicted scores.

#### Variance

##### Between School Variance

Between-school variance refers to the variation in the outcome variable (score) that is attributed to differences between schools. This variance component is crucial in multilevel modeling as it helps to understand how much of the total variance in scores can be explained by the differences between schools.

1.  **Constant Only Model**:
    -   In the constant only (null) model, the variance due to differences between schools (random intercept) is 61.02.
    -   This model does not include any explanatory variables and serves as a baseline to compare other models.
2.  **Model with Explanatory Variable (cohort90)**:
    -   When `cohort90` is added as an explanatory variable, the between-school variance reduces to 45.99.
    -   This reduction indicates that some of the variance between schools is explained by the cohort year.
3.  **Proportion of Unexplained Variance**:
    -   After accounting for the cohort effects, the proportion of unexplained variance due to differences between schools is calculated as: $$
        \frac{45.99}{45.99 + 219.29} = 17\%
        $$
    -   This means that 17% of the total unexplained variance in scores is attributable to differences between schools after accounting for the cohort effect.

##### Within School Variance

Within-school variance refers to the variation in the outcome variable (score) within schools. This component captures the differences in scores among students within the same school. Understanding this variance is essential for identifying how much of the total variance is due to individual differences within schools.

1.  **Constant Only Model**:
    -   In the constant only (null) model, the within-school variance (residual variance) is 258.36.
    -   This model does not include any explanatory variables and serves as a baseline to compare other models.
2.  **Model with Explanatory Variable (cohort90)**:
    -   When `cohort90` is added as an explanatory variable, the within-school variance reduces to 219.29.
    -   This reduction indicates that some of the variance within schools is explained by the cohort year.
3.  **Reduction in Variance**:
    -   The addition of `cohort90` reduces both the between-school and within-school variances.
    -   The between-school variance reduces from 61.02 to 45.99.
    -   The within-school variance reduces from 258.36 to 219.29.
    -   The decrease in within-school variance is expected because `cohort90` is a student-level variable, meaning it explains part of the individual differences within schools.
