---
title: "Transfer Function"
subtitle: "Machine Learning Regression"
author: "Dr Muhammad Saufi"
date: last-modified
format: 
  html:
    toc: true
    toc-title: Contents
    toc-location: left
    toc-depth: 5
    toc-expand: 1
    number-sections: true
    code-fold: true
    code-summary: "Code"
    code-link: true
    theme:
      light: united
      dark: cyborg
    css: styles.css
editor: visual
include-after-body: "footer.html"
---

# Introduction
A transfer function, also known as an activation function, is a crucial component of a neural network. It determines the output of a neuron given an input or a set of inputs. The primary role of the transfer function is to introduce non-linearity into the network, enabling it to learn and model complex patterns in the data.

# Types of Transfer Functions

## Linear Function
Adds inputs coming into a neuron and produces an output directly proportional to the input.

## Sigmoid (Logical Activation) Function
Maps input values to a range between 0 and 1.

$$
Y_T = \frac{1}{1 + e^{-Y}}
$$

## Tangent Hyperbolic Function (Tanh)
Maps input values to a range between -1 and 1.

# Example of Calculation

- Inputs: $X_1 = 3$, $X_2 = 1$, $X_3 = 2$
- Weights: $W_1 = 0.2$, $W_2 = 0.4$, $W_3 = 0.1$

## Calculate the Weighted Sum (Y)

$$
Y = X_1W_1 + X_2W_2 + X_3W_3
$$

$$
Y = (3 \times 0.2) + (1 \times 0.4) + (2 \times 0.1)
$$

$$
Y = 0.6 + 0.4 + 0.2 = 1.2
$$

## Apply the Sigmoid Function

$$
Y_T = \frac{1}{1 + e^{-Y}}
$$

Substituting $Y = 1.2$:

$$
Y_T = \frac{1}{1 + e^{-1.2}}
$$

Calculate $e^{-1.2} \approx 0.301$:

$$
Y_T = \frac{1}{1 + 0.301} = \frac{1}{1.301} \approx 0.77
$$

## Summary

- The weighted sum of the inputs ($Y$) is 1.2.
- The sigmoid function transforms $Y$ into $Y_T \approx 0.77$.

## Threshold Value

- In the context of neural networks, a threshold value is often used to decide if a neuron should be activated or not.
- Typically, for a sigmoid function, a common threshold is 0.5. If $Y_T$ is greater than 0.5, the neuron is considered activated (output 1); otherwise, it is not activated (output 0).
- In this example, $Y_T = 0.77$, which is greater than 0.5, so the neuron would be activated.
